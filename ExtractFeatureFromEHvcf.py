# -*- coding: utf-8 -*-
"""
Created on Thu Dec 17 17:41:58 2020

@author: Bharati Jadhav <bharati.jadhav@mssm.edu>, @Github:bharatij

Combine multiple vcf generated by Expansion Hunter V3.2.2 and create feature table for classifier
"""


import warnings
with warnings.catch_warnings():
    warnings.simplefilter("ignore", FutureWarning)
    import datetime
    from datetime import datetime
    import argparse
    import io
    import sys
    import os
    import numpy as np
    import pandas as pd
    
def parse_args():
    """Parse the input arguments, use '-h' for help"""
    parser = argparse.ArgumentParser(description='Combine multiple samples/loci vcf and generate feature table for classifier')
    
    parser.add_argument('--vcf_list', type=str, nargs='+', required = True,
                        help='Space separated list of vcf files for all samples.')
   
    parser.add_argument('--out', type=str, default = '',
                        help='Prefix for output file (suffix will be RF_Feature.tsv) (default: %(default)s)')

    parser.add_argument("--locus_file", type=str, required = True,
                        help="tsv file with list of SampldId and LocusId to test expansion with classifer.")
    return parser.parse_args()


def get_sample(fullpath):
    # Get the sample ID from the filename
    basename = os.path.basename(fullpath)
    return(basename.split('.')[0])

def get_locus(fname):
    # Get the sample ID and locus id to test with classifier
    try:
        locus = pd.read_csv(fname, sep='\t',names = ['SampleId', 'LocusId'])
        sys.stderr.write('Testing {0} expansions\n'.format(len(locus)))
        return(locus)
    except pd.errors.EmptyDataError:
        sys.exit('ERROR: file {0} was empty.\n'.format(locus))
    
  
def parse_vcf(filename):
    # Parse and combine all vcf files
    
    sample_id = get_sample(filename)
    try:
        with open(filename, 'r') as f:
            lines = [l for l in f if not l.startswith('##')]
        vcf_data = pd.read_csv(
        io.StringIO(''.join(lines)),
        dtype={'#CHROM': str, 'POS': int, 'ID': str, 'REF': str, 'ALT': str,
               'QUAL': str, 'FILTER': str, 'INFO': str},
        sep='\t'
        ).rename(columns={'#CHROM': 'chrom','POS': 'start'})
    
    except pd.io.common.EmptyDataError:
        sys.exit('ERROR: file {0} was empty.\n'.format(filename))
        
    vcf_data=vcf_data.drop(columns=['ID', 'REF','ALT','QUAL','FILTER','FORMAT'])
    
    vcf_data=vcf_data.rename(columns={vcf_data.columns[-1]: 'DATA'})
    vcf_data[['END','REF','RL','RU','VARID','REPID']] = vcf_data.INFO.str.split(";",expand=True) 
    vcf_data[['GT','SO','REPCN','REPCI','ADSP','ADFL','ADIR','LC']] = vcf_data.DATA.str.split(":",expand=True) 
    vcf_data=vcf_data.drop(columns=['INFO','DATA','REF','RL','REPID','GT', 'SO','REPCI','LC'])
    vcf_data['END'] = vcf_data.END.str.split("=").str[1].astype(int)
    vcf_data['RU'] = vcf_data.RU.str.split("=").str[1] 
    vcf_data['VARID'] = vcf_data.VARID.str.split("=").str[1] 
    vcf_data=vcf_data.rename(columns={'END':'end','RU':'RefUnit','VARID': 'LocusId'})
    vcf_data['SampleId']=sample_id
    vcf_data[['A1','A2']]=vcf_data.REPCN.str.split("/",expand=True)
    vcf_data[['IRR_A1','IRR_A2']]=vcf_data.ADIR.str.split("/",expand=True)
    vcf_data[['SPR_A1','SPR_A2']]=vcf_data.ADSP.str.split("/",expand=True)
    vcf_data[['FR_A1','FR_A2']]=vcf_data.ADFL.str.split("/",expand=True)
    vcf_data=vcf_data.drop(columns=['REPCN','ADSP','ADIR','ADFL'])
    
    vcf_data = vcf_data.replace([None], np.nan)
    vcf_data['A1temp'] = vcf_data['A1']
    vcf_data['A2temp'] = vcf_data['A2']
    vcf_data['A2']=vcf_data['A2'].fillna(vcf_data['A1'])    
    vcf_data.loc[(vcf_data['A2temp'].isnull()), 'A1'] = 0 
    
    vcf_data['A1temp'] = vcf_data['IRR_A1']
    vcf_data['A2temp'] = vcf_data['IRR_A2']
    vcf_data['IRR_A2'] = vcf_data['IRR_A2'].fillna(vcf_data['IRR_A1'])    
    vcf_data.loc[(vcf_data['A2temp'].isnull()), 'IRR_A1'] = 0 
 
    vcf_data['A1temp'] = vcf_data['SPR_A1']
    vcf_data['A2temp'] = vcf_data['SPR_A2']
    vcf_data['SPR_A2']=vcf_data['SPR_A2'].fillna(vcf_data['SPR_A1'])    
    vcf_data.loc[(vcf_data['A2temp'].isnull()), 'SPR_A1'] = 0 
 
    vcf_data['A1temp'] = vcf_data['FR_A1']
    vcf_data['A2temp'] = vcf_data['FR_A2']
    vcf_data['FR_A2']=vcf_data['FR_A2'].fillna(vcf_data['FR_A1'])    
    vcf_data.loc[(vcf_data['A2temp'].isnull()), 'FR_A1'] = 0 
       
    vcf_data['A1'] = vcf_data['A1'].astype(int)
    vcf_data['A2'] = vcf_data['A2'].astype(int)
    vcf_data['IRR_A1'] = vcf_data['IRR_A1'].astype(int)
    vcf_data['IRR_A2'] = vcf_data['IRR_A2'].astype(int)
    vcf_data['SPR_A1'] = vcf_data['SPR_A1'].astype(int)
    vcf_data['SPR_A2'] = vcf_data['SPR_A2'].astype(int)
    vcf_data['FR_A1'] = vcf_data['FR_A1'].astype(int)
    vcf_data['FR_A2'] = vcf_data['FR_A2'].astype(int)
    
    vcf_data=vcf_data.drop(columns=['A1temp','A2temp'])
    
    vcf_data = vcf_data.merge(locus_id[['SampleId','LocusId']])
    return(vcf_data)


def get_features(df):    
    df['LongAllele'] = df[['A1', 'A2']].max(axis=1)  
    df['IRR_Total'] = df['IRR_A1']+ df['IRR_A2']
    df['SPR_Total'] = df['SPR_A1']+ df['SPR_A2']
    df['FR_Total'] = df['FR_A1']+ df['FR_A2']
    
    df['IRR_Ratio'] = (df['IRR_A1'] / df['IRR_A2']).astype(float)
    df['FR_Ratio'] = (df['FR_A1'] / df['FR_A2']).astype(float)
    
    df['IRR_Ratio'] = df['IRR_Ratio'].replace(np.nan, 1)
    df['IRR_Ratio'] = df['IRR_Ratio'].replace(np.inf, 0)
   
    df['FR_Ratio'] = df['FR_Ratio'].replace(np.nan, 1)
    df['FR_Ratio'] = df['FR_Ratio'].replace(np.inf, 0)
    df['Total_Reads'] = df['IRR_Total'] + df['SPR_Total'] + df['FR_Total']
    return(df)
    
def main():
    # Parse command line arguments
    args = parse_args()

    base_filename = args.out
    vcf_files = args.vcf_list
    locus_id_file = args.locus_file
    results_suffix = '.RF_Feature.tsv'
    
    sys.stderr.write('Processing {0} samples\n'.format(len(vcf_files)))
    
    # Parse input data
    global locus_id 
    locus_id = get_locus(locus_id_file)
    print("Combining all sample vcfs ....")
    all_data = pd.concat( (parse_vcf(f) for f in vcf_files), ignore_index = True)
    print("Extracting features ....")
    feature_data=get_features(all_data)
    feature_data = feature_data.round({'IRR_Ratio': 2, 'FR_Ratio': 2})
    fout =  base_filename + results_suffix
    print("Writing output file ...." + fout)
    feature_data.to_csv(fout, sep= '\t', index = False, na_rep='NaN')
    print("Finished extracting features successfully!" + datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
 
if __name__ == '__main__':
    main()